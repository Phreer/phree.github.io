<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Phree Dream</title>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <link>http://localhost:4000/</link>
    <description>Phree Dream, about AI, Deep Learning and Life</description>
    <pubDate>Fri, 23 Mar 2018 00:56:01 +0800</pubDate>
    
      <item>
        <title>语音识别中的 CTC 算法详解</title>
        <link>/2018/03/22/ctc_algorithem.html</link>
        <guid isPermaLink="true">/2018/03/22/ctc_algorithem.html</guid>
        <description>&lt;h2 id=&quot;ctcconnectionist-temporal-classiﬁcation&quot;&gt;CTC(Connectionist Temporal Classiﬁcation)&lt;/h2&gt;
&lt;p&gt;在神经网络训练中用于训练序列化的数据, 比如说语音, 手写文字(虽然手写文字是一张图, 但不同的文字之间可以认为是按一定序列进行输入的, 因为要考虑前后的约束关系). 在数据量剧增的今天, 我们可以非常容易地获取大量语音数据, 但遗憾的是这些语音通常没有非常仔细的标注. 如何李用深度学习和大量数据的优势是语音识别领域的一个难题. CTC 的提出为使用深度神经网络进行语音识别奠定了基础.&lt;/p&gt;
&lt;h3 id=&quot;介绍&quot;&gt;介绍&lt;/h3&gt;
&lt;p&gt;在语音识别领域存在的一个问题是, 我们的训练数据往往只是语音片段和对应的文本, 语音序列和文本长度不同, 并且不是对齐的, 也就是, 我们不知道语音中的哪一帧是属于一个字, 也不知道一个字的长短. 这是因为进行对齐标注是一件非常耗费人力和时间的事情. 并且人与人的语速不同, 导致不可能使用一种强制的规则来强制确定一个字的长短. 这种难以对齐的问题也出现在手写字体识别中, 因为每个字占的大小也是不确定的.
CTC 正是为了解决这个问题而被提出的. CTC 用于把语音经过处理以后得到的特征映射为文本, 而对特征提取的过程并没有限制, 也即是说可以使用任何模型接到 CTC 中得到结果.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/ctc/alignment.svg&quot; alt=&quot;alignment&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;形式化问题&quot;&gt;形式化问题&lt;/h4&gt;
&lt;p&gt;CTC 网络将输入划分成固定长度的帧. 我们的目标是对给定符号输出符号集(如汉字表, 字母表)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{L^*}&lt;/script&gt;

&lt;p&gt;和训练数据集, &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt;, 训练集中每一个样本 &lt;script type=&quot;math/tex&quot;&gt;\mathbf{(x,z)}&lt;/script&gt;包含一个由T个向量组成的 &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; 维语音序列&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{x}=\{x_1, x_2,...,x_T\}&lt;/script&gt;

&lt;p&gt;和输出文本&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{z}=\{z_1,z_2,...,z_U\}&lt;/script&gt;

&lt;p&gt;希望找到映射 
&lt;script type=&quot;math/tex&quot;&gt;\mathbf{z}=h(\mathbf{x})&lt;/script&gt; .
事实上这个映射并不容易直接得到, CTC 通过一个巧妙的算法来得到这个映射.
CTC 网络先将输入的 &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; 维长度为 &lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; 向量序列 &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt; 映射为输出的 &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; 维长度为&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt;的向量序列 &lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}&lt;/script&gt;. &lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}=\{\mathbf{y^1, y^2, ..., y^T}\}&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{y^t}=\{y^t_1, y^t_2, ..., y^t_m\}&lt;/script&gt;

&lt;p&gt;其中 &lt;script type=&quot;math/tex&quot;&gt;y^t_k&lt;/script&gt; 表示&lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;时刻网络的第 &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; 个输出, 通常解释为输出低 &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;个符号的概率.
这个过程表示为
&lt;script type=&quot;math/tex&quot;&gt;\mathscr{N}:(\mathbb{R}^m)^T\mapsto (\mathbb{R}^n)^T&lt;/script&gt;. 
通常由一个 RNN 网络来完成, 如上图所示的 Alignment.
如此我们可以看到, 一个输出 &lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}&lt;/script&gt;, 可以对应一条路径, 我们将其表示为 &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt;. 每一条路径的概率为&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\pi|\mathbf{x})=\prod _{t=1}^Ty^t_{\pi_t}, \forall \pi \in L^T&lt;/script&gt;

&lt;p&gt;即一条路径的概率等于路径上各个符号输出概率的乘积(事实上, 这里是假设输出符号之间相互独立).
随后 CTC 需要对于连续相同的输出进行合并. 但是这种方法会出现一些问题, 比如说对于单词 hello, 输出的&lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}&lt;/script&gt;可能是 heelllooo, 进行合并以后会得到 helo 而不是 hello. 为了解决这个问题, CTC 中引入了一个特殊的 &amp;lt; blank &amp;gt; 字符, 最后这个字符是会被移去的. 我们期望它输出 heel&amp;lt; blank &amp;gt;loo, 最后就可以得到所期望的 hello. 使用&amp;lt; blank &amp;gt;还解决了语音中的停顿的问题, 同一段时间没有输出时, 也输出&amp;lt; blank &amp;gt;字符. 这时符号集&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
L'=L\cup &lt;blank&gt; %]]&gt;&lt;/script&gt;我们将这个合并和删除&amp;lt; blank &amp;gt;的过程记为&lt;script type=&quot;math/tex&quot;&gt;\mathcal{B}:L^{'T}\mapsto L^{\le T}&lt;/script&gt;, 将这个过程的输出记为&lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;, 有&lt;script type=&quot;math/tex&quot;&gt;\mathbf{l}=\mathcal{B}(\pi)&lt;/script&gt;显然这是一个多对一映射, 即可能有多个可能的路径对应一种可能的文本输出.
实际上, 我们所希望得到的就是&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h(\mathbf{x})=\arg \max_{l\in L^{\le T}}p(\mathbf{l|x})&lt;/script&gt;

&lt;p&gt;其中&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{l}|\mathbf{x})=\sum_{\pi}p(\pi|x), \pi \in \{\pi|\mathcal{B}(\pi)=\mathbf{l}\}&lt;/script&gt;

&lt;p&gt;即在所有可能的输出文本序列中找到概率最大的那一个, 而每一个输出文本序列的概率可以通过边沿概率分布公式得到, 即所有可能得到该输出文本的路径的概率之和.&lt;/p&gt;

&lt;h3 id=&quot;loss-function&quot;&gt;Loss Function&lt;/h3&gt;
&lt;p&gt;事实上直接优化得到上式也不是一件容易的事情. 因为这意味着我们需要遍历所有的路径来得到各个可能输出文本的概率. CTC 论文中提到两种方法可以简化这个步骤.
第一种方法比较简单, 我们可以简单地认为&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h(\mathbf{x})\approx \mathcal{B}(\pi^*)&lt;/script&gt;

&lt;p&gt;其中,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\pi^*=\arg \max _{\pi\in N^t}p(\pi|\mathbf{x})&lt;/script&gt;

&lt;p&gt;直观上理解就是直接找概率最大的路径, 认为其对应的输出一般也是概率最大的. 这样我们其实只需要选择每个&lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;中出现概率最大的符号. 可以解释为希望找一个成绩最好的班级, 但查看每一个学生的成绩又太过于繁琐, 于是只看成绩最好的学生的成绩.
从上面的例子可以看出, 这种方法事实上过于简化了, 很多情况下我们可能会遇到这种情况. 于是论文中还提出了前缀搜索解码(Prefix Search Decoding), 这种方法的结果普遍好于第一种方法.
事实上如果我们考量所有可能的路径, 我们会发现其实有很多路径是重复计算的, 有很多路径也是明显不可能的, 这启发我们使用动态规划和剪枝来去除冗余计算和淘汰不可能的路径. Prefix Search Decoding 算法类似于 HMM 模型中的前向-后向算法(F-B Algorithm).
我们首先定义&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_t(x)\equiv \sum_{\mathcal{B}(\pi_{1:t})=\mathbf{1:s}}\prod_{t'=1}^{t}y^{t'}_{\pi_{t'}}&lt;/script&gt;

&lt;p&gt;解释为经过&lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;步, 得到输出文本序列&lt;script type=&quot;math/tex&quot;&gt;\mathbf{l}_{1:s}&lt;/script&gt;的概率.
从而我们可以得到递推关系
…未完待续…&lt;/p&gt;

&lt;p&gt;CTC 假设在给定输入的情况下, 输出是条件独立的(事实上在一些情况下该假设是不成立的, 因此这也是 CTC 的一个主要缺点). 根据条件概率公式, 可以把它分解为. 每一种输出序列都可以看成是一条路径, 可以将其视为计算不同路径概率. 如果我们遍历所有路径计算概率, 计算量将是非常巨大的, 举个例子, 假设输出有 10 种不同的符号, 一个语音序列被分拆成 40 帧, 那么可能的路径将是 &lt;script type=&quot;math/tex&quot;&gt;10^{40}&lt;/script&gt;! 这是不可接受的. 幸运的是, 经过一些分析我们可以发现这种暴力算法中包含了很多冗余的计算, 熟悉算法的朋友可能已经发现了, 可以通过动态规划来高效地完成这一计算.
对于每一帧, 输出的概率分布 &lt;script type=&quot;math/tex&quot;&gt;P(a_t|X)&lt;/script&gt; 通常用 RNN 来实现.&lt;/p&gt;
</description>
        <pubDate>Thu, 22 Mar 2018 00:00:00 +0800</pubDate>
      </item>
    
      <item>
        <title>Summary of Batchnorm Algorithm</title>
        <link>/2018/02/26/bn2.html</link>
        <guid isPermaLink="true">/2018/02/26/bn2.html</guid>
        <description>&lt;h1 id=&quot;batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift&quot;&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/h1&gt;
&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;每一层输入的分布改变(covariate shift) -&amp;gt; 学习速率不能太快, 参数初始化需要很小心
使用BN -&amp;gt; 改善以上问题, 同时可以减少对Dropout的依赖.
文中对internal covariate shift的定义是&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;the change in the distribution of network activations due to the change in net- work parameters during training.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;其实covariate shift也可以用频域调整(domain adaptation)的方法缓解.
考虑一个例子, 假设网络某一层为sigmoid层, 有&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z=g(Wu+b)&lt;/script&gt;

&lt;p&gt;其中 &lt;script type=&quot;math/tex&quot;&gt;g(x)=\frac{1}{1+exp(-x)}&lt;/script&gt; 知道 &lt;script type=&quot;math/tex&quot;&gt;g'(x)&lt;/script&gt; 随着&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;增大而减小, 因此如果某一层的结果使得 &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; 分布在较大的区域, 则容易出现梯度饱和. 而且这种效应随着网络深度的增加, 很容易被扩大. 其实这个问题也可以通过使用ReLU来解决.&lt;/p&gt;

&lt;h2 id=&quot;batch-normalization&quot;&gt;Batch Normalization&lt;/h2&gt;
&lt;p&gt;Algorithm BN comes as follows:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Input:&lt;/strong&gt; Values of &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; over a mini-batch: &lt;script type=&quot;math/tex&quot;&gt;\mathcal{B}=\{x_{1...m}\}&lt;/script&gt;;
Parameters to be learned: &lt;script type=&quot;math/tex&quot;&gt;\gamma&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt;;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\{y_i=BN_{\gamma,\beta}(x_i)\}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
  &amp; \mu_{\mathcal{B}}=\frac{1}{m}\sum_{i=1}^{m}x_i \\
  &amp; \sigma_{\mathcal{B}}^2=\frac{1}{m}\sum_{i=1}^m(x_i-\mu_B)^2 \\
  &amp; \hat{x_{i}}=\frac{x_i-\mu_\mathcal{B}}{\sqrt{\sigma_{\mathcal{B}}^2+\epsilon}} \\
  &amp; y_i=\gamma\hat{x_i}+\beta \equiv BN_{\gamma,\beta}(x_i)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Seems to be very easy. As we can see, the internal variable (we can cosider it as output of a layer) $\hat{x_i}$ has 0 mean and 1 variance, which makes it work. Later, we use $\beta$ and $\gamma$ to reconstruct the data, preserving the presence capability of the network.&lt;/p&gt;

&lt;h2 id=&quot;inference-network&quot;&gt;Inference Network&lt;/h2&gt;
&lt;p&gt;BN algorithm is used for accelerating training process, so it’s unnecessary during inference (or generation). We use &lt;script type=&quot;math/tex&quot;&gt;E[X] \leftarrow E[\mu_{\mathcal{B}}]&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;Var[x] \leftarrow \frac{m}{m-1}E_{\mathcal{B}}[\sigma_{\mathcal{B}}^2]&lt;/script&gt; to estimate the mean and variance of the input.&lt;/p&gt;

&lt;h2 id=&quot;convolutional-networks-case&quot;&gt;Convolutional Networks Case&lt;/h2&gt;
&lt;p&gt;When using batchnorm in convolutional networks, we should note:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;different feature maps are batch normalized seperately and have their own parameters(&lt;script type=&quot;math/tex&quot;&gt;\beta^{(k)}, \gamma^{(k)}&lt;/script&gt;)&lt;/li&gt;
  &lt;li&gt;different locations in a single feature map are jointly normalized.
    &lt;h2 id=&quot;something-more&quot;&gt;Something More&lt;/h2&gt;
    &lt;p&gt;In the original paper, the authors added batchnorm before an activation, and analyze based on this fact. However, some other researchers’ experiment argued that batchnorm after activation seems to have better performance.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;理论依据&quot;&gt;理论依据&lt;/h2&gt;
&lt;p&gt;LeCun曾经证明过, 如果输入是经过白化(Whitened, 就是均值为0, 方差为1)网络会收敛得更快.&lt;/p&gt;
</description>
        <pubDate>Mon, 26 Feb 2018 00:00:00 +0800</pubDate>
      </item>
    
      <item>
        <title>这是我的第一篇博文, 用于测试</title>
        <link>/2018/02/18/first-article.html</link>
        <guid isPermaLink="true">/2018/02/18/first-article.html</guid>
        <description>&lt;p&gt;大年初三, 祝大家新年快乐!&lt;/p&gt;

&lt;p&gt;建立这个博客的目的是分享在学习过程中的心得, 认识一些志同道合的朋友. 为了建立这个博客还是花了不少时间呢, 希望能够用心维护. 虽然现在还很简陋, 但是以后会慢慢改进的!&lt;/p&gt;
</description>
        <pubDate>Sun, 18 Feb 2018 00:00:00 +0800</pubDate>
      </item>
    
  </channel>
</rss>