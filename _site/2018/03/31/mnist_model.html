<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <!-- JQuery (used for bootstrap and jekyll search) -->
    <script src="/assets/js/jquery-3.2.1.min.js" ></script>
    
    <!-- Main JS (navbar.js and katex_init.js)-->
    <script defer=true src="/assets/js/main.min.js"></script>
    
    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">

    <!--Favicon-->
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- Canonical -->
    <link rel="canonical" href="http://localhost:4000/2018/03/31/mnist_model.html">

    <!-- RSS -->
    <link rel="alternate" type="application/atom+xml" title="Phree Dream" href="http://localhost:4000///feed.xml"/>

    <!-- Font Awesome -->
    <!-- <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> -->
    <link rel="stylesheet" type="text/css" href="/assets/css/font-awesome.min.css">

    <!-- Google Fonts -->
    
    <link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css"> 
    

    <!-- KaTeX 0.8.3 -->
    
    <!--<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.js"></script> -->
    <link rel="stylesheet" type="text/css" href="/assets/css/katex.min.css">
    <script src="/assets/js/katex.min.js">
    </script>
    

    <!-- Google Analytics -->
    
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-110451933-1', 'auto');
        ga('send', 'pageview');

    </script>
    
    
    <!-- seo tags -->
    <!-- Begin Jekyll SEO tag v2.4.0 -->
<title>使用 CNNs 实现的 Mnist 分类模型及 Demo, 正确率 0.996+</title>
<meta name="generator" content="Jekyll v3.7.2" />
<meta property="og:title" content="使用 CNNs 实现的 Mnist 分类模型及 Demo, 正确率 0.996+" />
<meta name="author" content="Phree" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Features 99.619% 测试集正确率 可视化网络激活层的 feature map 拍照识别数字 所使用的技术 深度学习技术 He Initializer, 即 分别为输入, 输出神经元的个数. Residual Block Dropout Adam Optimizer Data Augmentation Model Emsemble 为了增强泛化能力, 一共训练了 3 个网络, 将 3 个模型的输出加到一起进行判断. 训练过程使用的算法是 AdaBoost. Capture Image Sharpening 使拍摄得到的图片拟合训练/测试数据集的分布 软件开发技术 demo 程序界面: tkinter 所使用的的模型结构 Data-augmentation and Dropout 在训练过程中, 发现由于使用了比较深的网络, 导致了比较严重的过拟合, 因此考虑使用 Data-augmentation 和 Dropout 来增强泛化能力. 以下是这两种技术对训练过程和泛化性能的影响. 可以看到, 不使用 Data-augmentation 将会使 loss 迅速减少为 0, 明显过拟合, 此时几乎没有梯度下降. 而使用了 Data-augmentation 以后, loss 会产生震荡, 加入 Dropout 以后, 这种现象更加明显. Data-augmentation Dropout Training Set Accuracy Test Set Accuracy no no 1.0 0.991987 yes no 0.997396 0.994691 yes yes 0.997095 0.994591 Networks Boosting 训练过程中发现模型正确率一般在 0.9955 左右徘徊, 达不到所需要的 0.996, 或者只能偶尔达到 0.996, 因此使用 Boosting 方法, 训练 3 个网络进行判决. 使用的算法为 AdaBoosting. 使用 Boosting 以后每次训练结果都能达到 0.996. Capture Image Sharpening 在训练完网络以后, 测试了模型的实际应用效果, 发现结果并不太好, 很多情况都会被识别为 8. 观察以后发现这是由于实际应用输入的图片和 Mnist 训练集和测试集的分布有较大的差别. 可以看到, Mnist 数据集的数据分布主要是在接近 0 和 255 间. 而我们通过摄像头拍摄的数据受限于光照条件等原因, 灰度往往集中在直方图的中间. 因此必须修正输入图像的直方图. 开始使用的方法是对图像进行伽马变换(当时数字图像处理课刚好上到图像灰度变换部分), 即 为输入像素, 为 3.0 ~ 7.0 之间的常数. 进过该变换以后得到 这样与测试数据集分布更为接近一些, 测试结果也大为改观. 之后数字图像处理课程又学习了直方图规定化处理, 因此之后可以考虑使用这种方法进一步拟合测试数据集. Demo 主界面 开启摄像头, 可以进行拍照并截取数字 选择一张图片, 并进行测试 可以看到, 测试结果正确. 本人尝试了一些手写体和印刷体数字, 都能够识别正确. 可视化 feature map 直接将每一个 feature map显示出来结果如下所示 另一种可视化技术使用论文 Visualize and Understanding Convolutional Neural Networks 中的方法, 即对每一个 feature map 进行(反)激活, unpooling 和 deconvolution. GitHub 上已经有一个比较完善的实现[4], 因此配置以后直接调用即可. 结果如下所示: 分析 网络的确能够提取到图像不同的特征, 但由于 Mnist 数据集分布比较单一, 特征也不太多, 并不需要用太深的网络来处理. 可以看到, feature map 中有很大部分都有非常相似的结果. 使用太深的网络还带来严重的过拟合问题, 如前所述, 必须采样强有力的抗过拟合方法才能改善泛化性能. 因此之后尝试训练了一个比较浅的网络, 正确率为 0.9961939102564102. 网络结构如下 结果: Model Training Set Accuracy Test Set Accuracy 1 0.997095 0.99369 2 0.9999 0.98758 3 1 0.992188 Emsembled   0.9961939102564102 可以看到, 模型性能与深层网络基本相同, 甚至更优. 证明之前的推断正确. 其他讨论 实验中比较了 SGD 优化算法和 Adam 优化算法的收敛速度, 发现 Adam 的收敛速度确实快很多, 且震荡现象不明显. 实验中还尝试了使用 BatchNorm, 但提升并不大. 猜测是由于 BatchNorm 主要用于提高收敛速度, 而实际收敛速度已经非常快了(大约 30k loss 就能达到一个很低的水平), 因此加入了 BatchNorm 反而降低了模型的性能. 感想 Mnist 的分类之前虽然尝试过, 但并没有对正确率有太高的要求, 且初次接触, 没有进行太深入的探究. 本次任务要求 0.996 的正确率, 虽然对于深度学习来说拟合 Mnist 数据集并不是一件太难的事情, 但要达到很高的正确率还是需要比较认真考量模型结构, 调整参数. 本次任务过程中我也尽量尝试了之前论文, 博客上看到的技术, 比如 Dropout, BatchNorm, Feature map 可视化技术等等. 所以说这次体验收获还是非常大的. 参考文献 Visualize and Understanding Convolutional Neural Networks 李航. 统计学习方法 Feature Visualizing https://github.com/InFoCusp/tf_cnnvis/ https://distill.pub/2017/feature-visualization/ http://link.springer.com/10.1007/978-3-319-10590-1_53%5Cnhttp://arxiv.org/abs/1311.2901%5Cnpapers3://publication/uuid/44feb4b1-873a-4443-8baa-1730ecd16291" />
<meta property="og:description" content="Features 99.619% 测试集正确率 可视化网络激活层的 feature map 拍照识别数字 所使用的技术 深度学习技术 He Initializer, 即 分别为输入, 输出神经元的个数. Residual Block Dropout Adam Optimizer Data Augmentation Model Emsemble 为了增强泛化能力, 一共训练了 3 个网络, 将 3 个模型的输出加到一起进行判断. 训练过程使用的算法是 AdaBoost. Capture Image Sharpening 使拍摄得到的图片拟合训练/测试数据集的分布 软件开发技术 demo 程序界面: tkinter 所使用的的模型结构 Data-augmentation and Dropout 在训练过程中, 发现由于使用了比较深的网络, 导致了比较严重的过拟合, 因此考虑使用 Data-augmentation 和 Dropout 来增强泛化能力. 以下是这两种技术对训练过程和泛化性能的影响. 可以看到, 不使用 Data-augmentation 将会使 loss 迅速减少为 0, 明显过拟合, 此时几乎没有梯度下降. 而使用了 Data-augmentation 以后, loss 会产生震荡, 加入 Dropout 以后, 这种现象更加明显. Data-augmentation Dropout Training Set Accuracy Test Set Accuracy no no 1.0 0.991987 yes no 0.997396 0.994691 yes yes 0.997095 0.994591 Networks Boosting 训练过程中发现模型正确率一般在 0.9955 左右徘徊, 达不到所需要的 0.996, 或者只能偶尔达到 0.996, 因此使用 Boosting 方法, 训练 3 个网络进行判决. 使用的算法为 AdaBoosting. 使用 Boosting 以后每次训练结果都能达到 0.996. Capture Image Sharpening 在训练完网络以后, 测试了模型的实际应用效果, 发现结果并不太好, 很多情况都会被识别为 8. 观察以后发现这是由于实际应用输入的图片和 Mnist 训练集和测试集的分布有较大的差别. 可以看到, Mnist 数据集的数据分布主要是在接近 0 和 255 间. 而我们通过摄像头拍摄的数据受限于光照条件等原因, 灰度往往集中在直方图的中间. 因此必须修正输入图像的直方图. 开始使用的方法是对图像进行伽马变换(当时数字图像处理课刚好上到图像灰度变换部分), 即 为输入像素, 为 3.0 ~ 7.0 之间的常数. 进过该变换以后得到 这样与测试数据集分布更为接近一些, 测试结果也大为改观. 之后数字图像处理课程又学习了直方图规定化处理, 因此之后可以考虑使用这种方法进一步拟合测试数据集. Demo 主界面 开启摄像头, 可以进行拍照并截取数字 选择一张图片, 并进行测试 可以看到, 测试结果正确. 本人尝试了一些手写体和印刷体数字, 都能够识别正确. 可视化 feature map 直接将每一个 feature map显示出来结果如下所示 另一种可视化技术使用论文 Visualize and Understanding Convolutional Neural Networks 中的方法, 即对每一个 feature map 进行(反)激活, unpooling 和 deconvolution. GitHub 上已经有一个比较完善的实现[4], 因此配置以后直接调用即可. 结果如下所示: 分析 网络的确能够提取到图像不同的特征, 但由于 Mnist 数据集分布比较单一, 特征也不太多, 并不需要用太深的网络来处理. 可以看到, feature map 中有很大部分都有非常相似的结果. 使用太深的网络还带来严重的过拟合问题, 如前所述, 必须采样强有力的抗过拟合方法才能改善泛化性能. 因此之后尝试训练了一个比较浅的网络, 正确率为 0.9961939102564102. 网络结构如下 结果: Model Training Set Accuracy Test Set Accuracy 1 0.997095 0.99369 2 0.9999 0.98758 3 1 0.992188 Emsembled   0.9961939102564102 可以看到, 模型性能与深层网络基本相同, 甚至更优. 证明之前的推断正确. 其他讨论 实验中比较了 SGD 优化算法和 Adam 优化算法的收敛速度, 发现 Adam 的收敛速度确实快很多, 且震荡现象不明显. 实验中还尝试了使用 BatchNorm, 但提升并不大. 猜测是由于 BatchNorm 主要用于提高收敛速度, 而实际收敛速度已经非常快了(大约 30k loss 就能达到一个很低的水平), 因此加入了 BatchNorm 反而降低了模型的性能. 感想 Mnist 的分类之前虽然尝试过, 但并没有对正确率有太高的要求, 且初次接触, 没有进行太深入的探究. 本次任务要求 0.996 的正确率, 虽然对于深度学习来说拟合 Mnist 数据集并不是一件太难的事情, 但要达到很高的正确率还是需要比较认真考量模型结构, 调整参数. 本次任务过程中我也尽量尝试了之前论文, 博客上看到的技术, 比如 Dropout, BatchNorm, Feature map 可视化技术等等. 所以说这次体验收获还是非常大的. 参考文献 Visualize and Understanding Convolutional Neural Networks 李航. 统计学习方法 Feature Visualizing https://github.com/InFoCusp/tf_cnnvis/ https://distill.pub/2017/feature-visualization/ http://link.springer.com/10.1007/978-3-319-10590-1_53%5Cnhttp://arxiv.org/abs/1311.2901%5Cnpapers3://publication/uuid/44feb4b1-873a-4443-8baa-1730ecd16291" />
<link rel="canonical" href="http://localhost:4000/2018/03/31/mnist_model.html" />
<meta property="og:url" content="http://localhost:4000/2018/03/31/mnist_model.html" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-03-31T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"Features 99.619% 测试集正确率 可视化网络激活层的 feature map 拍照识别数字 所使用的技术 深度学习技术 He Initializer, 即 分别为输入, 输出神经元的个数. Residual Block Dropout Adam Optimizer Data Augmentation Model Emsemble 为了增强泛化能力, 一共训练了 3 个网络, 将 3 个模型的输出加到一起进行判断. 训练过程使用的算法是 AdaBoost. Capture Image Sharpening 使拍摄得到的图片拟合训练/测试数据集的分布 软件开发技术 demo 程序界面: tkinter 所使用的的模型结构 Data-augmentation and Dropout 在训练过程中, 发现由于使用了比较深的网络, 导致了比较严重的过拟合, 因此考虑使用 Data-augmentation 和 Dropout 来增强泛化能力. 以下是这两种技术对训练过程和泛化性能的影响. 可以看到, 不使用 Data-augmentation 将会使 loss 迅速减少为 0, 明显过拟合, 此时几乎没有梯度下降. 而使用了 Data-augmentation 以后, loss 会产生震荡, 加入 Dropout 以后, 这种现象更加明显. Data-augmentation Dropout Training Set Accuracy Test Set Accuracy no no 1.0 0.991987 yes no 0.997396 0.994691 yes yes 0.997095 0.994591 Networks Boosting 训练过程中发现模型正确率一般在 0.9955 左右徘徊, 达不到所需要的 0.996, 或者只能偶尔达到 0.996, 因此使用 Boosting 方法, 训练 3 个网络进行判决. 使用的算法为 AdaBoosting. 使用 Boosting 以后每次训练结果都能达到 0.996. Capture Image Sharpening 在训练完网络以后, 测试了模型的实际应用效果, 发现结果并不太好, 很多情况都会被识别为 8. 观察以后发现这是由于实际应用输入的图片和 Mnist 训练集和测试集的分布有较大的差别. 可以看到, Mnist 数据集的数据分布主要是在接近 0 和 255 间. 而我们通过摄像头拍摄的数据受限于光照条件等原因, 灰度往往集中在直方图的中间. 因此必须修正输入图像的直方图. 开始使用的方法是对图像进行伽马变换(当时数字图像处理课刚好上到图像灰度变换部分), 即 为输入像素, 为 3.0 ~ 7.0 之间的常数. 进过该变换以后得到 这样与测试数据集分布更为接近一些, 测试结果也大为改观. 之后数字图像处理课程又学习了直方图规定化处理, 因此之后可以考虑使用这种方法进一步拟合测试数据集. Demo 主界面 开启摄像头, 可以进行拍照并截取数字 选择一张图片, 并进行测试 可以看到, 测试结果正确. 本人尝试了一些手写体和印刷体数字, 都能够识别正确. 可视化 feature map 直接将每一个 feature map显示出来结果如下所示 另一种可视化技术使用论文 Visualize and Understanding Convolutional Neural Networks 中的方法, 即对每一个 feature map 进行(反)激活, unpooling 和 deconvolution. GitHub 上已经有一个比较完善的实现[4], 因此配置以后直接调用即可. 结果如下所示: 分析 网络的确能够提取到图像不同的特征, 但由于 Mnist 数据集分布比较单一, 特征也不太多, 并不需要用太深的网络来处理. 可以看到, feature map 中有很大部分都有非常相似的结果. 使用太深的网络还带来严重的过拟合问题, 如前所述, 必须采样强有力的抗过拟合方法才能改善泛化性能. 因此之后尝试训练了一个比较浅的网络, 正确率为 0.9961939102564102. 网络结构如下 结果: Model Training Set Accuracy Test Set Accuracy 1 0.997095 0.99369 2 0.9999 0.98758 3 1 0.992188 Emsembled   0.9961939102564102 可以看到, 模型性能与深层网络基本相同, 甚至更优. 证明之前的推断正确. 其他讨论 实验中比较了 SGD 优化算法和 Adam 优化算法的收敛速度, 发现 Adam 的收敛速度确实快很多, 且震荡现象不明显. 实验中还尝试了使用 BatchNorm, 但提升并不大. 猜测是由于 BatchNorm 主要用于提高收敛速度, 而实际收敛速度已经非常快了(大约 30k loss 就能达到一个很低的水平), 因此加入了 BatchNorm 反而降低了模型的性能. 感想 Mnist 的分类之前虽然尝试过, 但并没有对正确率有太高的要求, 且初次接触, 没有进行太深入的探究. 本次任务要求 0.996 的正确率, 虽然对于深度学习来说拟合 Mnist 数据集并不是一件太难的事情, 但要达到很高的正确率还是需要比较认真考量模型结构, 调整参数. 本次任务过程中我也尽量尝试了之前论文, 博客上看到的技术, 比如 Dropout, BatchNorm, Feature map 可视化技术等等. 所以说这次体验收获还是非常大的. 参考文献 Visualize and Understanding Convolutional Neural Networks 李航. 统计学习方法 Feature Visualizing https://github.com/InFoCusp/tf_cnnvis/ https://distill.pub/2017/feature-visualization/ http://link.springer.com/10.1007/978-3-319-10590-1_53%5Cnhttp://arxiv.org/abs/1311.2901%5Cnpapers3://publication/uuid/44feb4b1-873a-4443-8baa-1730ecd16291","author":{"@type":"Person","name":"Phree"},"@type":"BlogPosting","url":"http://localhost:4000/2018/03/31/mnist_model.html","headline":"使用 CNNs 实现的 Mnist 分类模型及 Demo, 正确率 0.996+","dateModified":"2018-03-31T00:00:00+08:00","datePublished":"2018-03-31T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2018/03/31/mnist_model.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <!-- Manual seo tags -->
    <!--
    <title>使用 CNNs 实现的 Mnist 分类模型及 Demo, 正确率 0.996+ | Phree Dream</title>
    <meta name="description" content="Features  99.619% 测试集正确率  可视化网络激活层的 feature map  拍照识别数字所使用的技术深度学习技术  He Initializer, 即分别为输入, 输出神经元的个数.  Residual Block  Dropout  Adam Optimizer  Data Augment...">
    -->
</head>

  <body>
    <header class="site-header">
    
    <!-- Logo and title -->
	<div class="branding">
		<a href="/">
			<img class="avatar" src="/assets/img/triangle.svg" alt=""/>
		</a>

		<h1 class="site-title">
			<a href="/">Phree Dream</a>
		</h1>
	</div>
    
    <!-- Toggle menu -->
    <nav class="clear">
    <a id="pull" class="toggle" href="#">
    <i class="fa fa-bars fa-lg"></i>
    </a>
    
    <!-- Menu -->
    <ul>
        
        
        
        
        <li>
            <a class="clear" href="/about/">
                关于
            </a>
        </li>
        
        
        
        <li>
            <a class="clear" href="/archives/">
                归档
            </a>
        </li>
        
        
        
        
        
        
        
        
        
        
        
        
        
         
        
        
        <li>
            <a class="clear" href="http://localhost:4000/search">
                <i class="fa fa-search" aria-hidden="true"></i>
            </a>
        </li>
        
        
        <li>
            <a class="clear" href="http://localhost:4000/tags">
                <i class="fa fa-tags" aria-hidden="true"></i>
            </a>
        </li>
        
        
    </ul>
        
	</nav>
</header>

    <div class="content">
      <article >
  <header id="main" style="background-image: url('/')">
    <h1 id="%E4%BD%BF%E7%94%A8+CNNs+%E5%AE%9E%E7%8E%B0%E7%9A%84+Mnist+%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%8F%8A+Demo%2C+%E6%AD%A3%E7%A1%AE%E7%8E%87+0.996%2B" class="title">使用 CNNs 实现的 Mnist 分类模型及 Demo, 正确率 0.996+</h1>
    <p class="meta">
    March 31, 2018
     - Phree
    </p>
  </header>
  <section class="post-content"><h2 id="features">Features</h2>
<ul>
  <li>99.619% 测试集正确率</li>
  <li>可视化网络激活层的 feature map</li>
  <li>拍照识别数字</li>
</ul>

<h2 id="所使用的技术">所使用的技术</h2>
<h3 id="深度学习技术">深度学习技术</h3>
<ul>
  <li>He Initializer, 即</li>
</ul>

<script type="math/tex; mode=display">\sigma = \sqrt{\frac{2}{f_{in}+f_{out}}}</script>

<p><script type="math/tex">f_{in}, f_{out}</script>分别为输入, 输出神经元的个数.</p>
<ul>
  <li>Residual Block</li>
  <li>Dropout</li>
  <li>Adam Optimizer</li>
  <li>Data Augmentation</li>
  <li>Model Emsemble
为了增强泛化能力, 一共训练了 3 个网络, 将 3 个模型的输出加到一起进行判断. 训练过程使用的算法是 AdaBoost.</li>
  <li>Capture Image Sharpening
使拍摄得到的图片拟合训练/测试数据集的分布</li>
</ul>

<h3 id="软件开发技术">软件开发技术</h3>
<ul>
  <li>demo 程序界面: tkinter</li>
</ul>

<h2 id="所使用的的模型结构">所使用的的模型结构</h2>
<p><img src="/assets/img/2018-3-31/网络结构.svg" alt="Network Architecture" /></p>

<h2 id="data-augmentation-and-dropout">Data-augmentation and Dropout</h2>
<p>在训练过程中, 发现由于使用了比较深的网络, 导致了比较严重的过拟合, 因此考虑使用 Data-augmentation 和 Dropout 来增强泛化能力. 以下是这两种技术对训练过程和泛化性能的影响.</p>

<p><img src="/assets/img/2018-3-31/loss.png" alt="Loss" /></p>

<p>可以看到, 不使用 Data-augmentation 将会使 loss 迅速减少为 0, 明显过拟合, 此时几乎没有梯度下降. 而使用了 Data-augmentation 以后, loss 会产生震荡, 加入 Dropout 以后, 这种现象更加明显.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Data-augmentation</th>
      <th style="text-align: left">Dropout</th>
      <th style="text-align: left">Training Set Accuracy</th>
      <th style="text-align: left">Test Set Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">no</td>
      <td style="text-align: left">no</td>
      <td style="text-align: left">1.0</td>
      <td style="text-align: left">0.991987</td>
    </tr>
    <tr>
      <td style="text-align: left">yes</td>
      <td style="text-align: left">no</td>
      <td style="text-align: left">0.997396</td>
      <td style="text-align: left">0.994691</td>
    </tr>
    <tr>
      <td style="text-align: left">yes</td>
      <td style="text-align: left">yes</td>
      <td style="text-align: left">0.997095</td>
      <td style="text-align: left">0.994591</td>
    </tr>
  </tbody>
</table>

<h2 id="networks-boosting">Networks Boosting</h2>
<p>训练过程中发现模型正确率一般在 0.9955 左右徘徊, 达不到所需要的 0.996, 或者只能偶尔达到 0.996, 因此使用 Boosting 方法, 训练 3 个网络进行判决. 使用的算法为 AdaBoosting.
使用 Boosting 以后每次训练结果都能达到 0.996.</p>

<h2 id="capture-image-sharpening">Capture Image Sharpening</h2>
<p>在训练完网络以后, 测试了模型的实际应用效果, 发现结果并不太好, 很多情况都会被识别为 8. 观察以后发现这是由于实际应用输入的图片和 Mnist 训练集和测试集的分布有较大的差别.</p>

<p><img src="/assets/img/2018-3-31/mnist_samples.png" alt="Mnist Samples" /></p>

<p><img src="/assets/img/2018-3-31/mnist_histogram.png" alt="Mnist Histogram" /></p>

<p>可以看到, Mnist 数据集的数据分布主要是在接近 0 和 255 间. 而我们通过摄像头拍摄的数据受限于光照条件等原因, 灰度往往集中在直方图的中间.</p>

<p><img src="/assets/img/2018-3-31/original.png" alt="Original Image Histogram" /></p>

<p>因此必须修正输入图像的直方图. 开始使用的方法是对图像进行伽马变换(当时数字图像处理课刚好上到图像灰度变换部分), 即</p>

<script type="math/tex; mode=display">f(r)=cr^\gamma</script>

<p><script type="math/tex">r</script> 为输入像素, <script type="math/tex">\gamma</script> 为 3.0 ~ 7.0 之间的常数.
进过该变换以后得到</p>

<p><img src="/assets/img/2018-3-31/augmented.png" alt="Augmented Photo" /></p>

<p>这样与测试数据集分布更为接近一些, 测试结果也大为改观. 之后数字图像处理课程又学习了直方图规定化处理, 因此之后可以考虑使用这种方法进一步拟合测试数据集.</p>

<h2 id="demo">Demo</h2>

<h3 id="主界面">主界面</h3>

<p><img src="/assets/img/2018-3-31/main_window.jpg" alt="Main Window" /></p>

<p>开启摄像头, 可以进行拍照并截取数字</p>

<p><img src="/assets/img/2018-3-31/camera.jpg" alt="Capture Image from Camera" /></p>

<p>选择一张图片, 并进行测试</p>

<p><img src="/assets/img/2018-3-31/detect.jpg" alt="Detect" /></p>

<p>可以看到, 测试结果正确. 本人尝试了一些手写体和印刷体数字, 都能够识别正确.</p>

<h3 id="可视化-feature-map">可视化 feature map</h3>
<p>直接将每一个 feature map显示出来结果如下所示</p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l002_conv2d/activations/grid_activation.png" alt="第一次卷积" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l003_conv2d/activations/grid_activation.png" alt="第二次卷积" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l004_relu/activations/grid_activation.png" alt="第一次激活" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l005_conv2d/activations/grid_activation.png" alt="第三次卷积" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l006_relu/activations/grid_activation.png" alt="第二次激活" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l007_conv2d/activations/grid_activation.png" alt="第四次卷积" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l008_conv2d/activations/grid_activation.png" alt="第五次卷积" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l009_relu/activations/grid_activation.png" alt="第三次激活" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l010_conv2d/activations/grid_activation.png" alt="第六次卷积" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l012_relu/activations/grid_activation.png" alt="第四次激活" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l013_conv2d/activations/grid_activation.png" alt="第七次卷积" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l015_relu/activations/grid_activation.png" alt="第五次激活" /></p>

<p>另一种可视化技术使用论文 Visualize and Understanding Convolutional Neural Networks 中的方法, 即对每一个 feature map 进行(反)激活, unpooling 和 deconvolution. GitHub 上已经有一个比较完善的实现[4], 因此配置以后直接调用即可. 结果如下所示:</p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l004_relu/deconvolution/grid_image.png" alt="第一次激活" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l006_relu/deconvolution/grid_image.png" alt="第二次激活" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l009_relu/deconvolution/grid_image.png" alt="第三次激活" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l012_relu/deconvolution/grid_image.png" alt="第四次激活" /></p>

<p><img src="/assets/img/2018-3-31/input_mnist_classifier_v3_3_b1_l015_relu/deconvolution/grid_image.png" alt="第五次激活" /></p>

<h3 id="分析">分析</h3>
<p>网络的确能够提取到图像不同的特征, 但由于 Mnist 数据集分布比较单一, 特征也不太多, 并不需要用太深的网络来处理. 可以看到, feature map 中有很大部分都有非常相似的结果. 使用太深的网络还带来严重的过拟合问题, 如前所述, 必须采样强有力的抗过拟合方法才能改善泛化性能. 因此之后尝试训练了一个比较浅的网络, 正确率为 0.9961939102564102. 网络结构如下</p>

<p><img src="/assets/img/2018-3-31/网络结构2.svg" alt="网络结构2" /></p>

<p>结果:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Model</th>
      <th style="text-align: left">Training Set Accuracy</th>
      <th style="text-align: left">Test Set Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">1</td>
      <td style="text-align: left">0.997095</td>
      <td style="text-align: left">0.99369</td>
    </tr>
    <tr>
      <td style="text-align: left">2</td>
      <td style="text-align: left">0.9999</td>
      <td style="text-align: left">0.98758</td>
    </tr>
    <tr>
      <td style="text-align: left">3</td>
      <td style="text-align: left">1</td>
      <td style="text-align: left">0.992188</td>
    </tr>
    <tr>
      <td style="text-align: left">Emsembled</td>
      <td style="text-align: left"> </td>
      <td style="text-align: left">0.9961939102564102</td>
    </tr>
  </tbody>
</table>

<p>可以看到, 模型性能与深层网络基本相同, 甚至更优. 证明之前的推断正确.</p>

<h2 id="其他讨论">其他讨论</h2>
<ul>
  <li>实验中比较了 SGD 优化算法和 Adam 优化算法的收敛速度, 发现 Adam 的收敛速度确实快很多, 且震荡现象不明显.</li>
  <li>实验中还尝试了使用 BatchNorm, 但提升并不大. 猜测是由于 BatchNorm 主要用于提高收敛速度, 而实际收敛速度已经非常快了(大约 30k loss 就能达到一个很低的水平), 因此加入了 BatchNorm 反而降低了模型的性能.</li>
</ul>

<h2 id="感想">感想</h2>
<p>Mnist 的分类之前虽然尝试过, 但并没有对正确率有太高的要求, 且初次接触, 没有进行太深入的探究. 本次任务要求 0.996 的正确率, 虽然对于深度学习来说拟合 Mnist 数据集并不是一件太难的事情, 但要达到很高的正确率还是需要比较认真考量模型结构, 调整参数. 本次任务过程中我也尽量尝试了之前论文, 博客上看到的技术, 比如 Dropout, BatchNorm, Feature map 可视化技术等等. 所以说这次体验收获还是非常大的.</p>

<h2 id="参考文献">参考文献</h2>
<ul>
  <li>Visualize and Understanding Convolutional Neural Networks</li>
  <li>李航. 统计学习方法</li>
  <li>Feature Visualizing</li>
  <li>https://github.com/InFoCusp/tf_cnnvis/</li>
  <li>https://distill.pub/2017/feature-visualization/</li>
  <li>http://link.springer.com/10.1007/978-3-319-10590-1_53%5Cnhttp://arxiv.org/abs/1311.2901%5Cnpapers3://publication/uuid/44feb4b1-873a-4443-8baa-1730ecd16291</li>
</ul>
</section>
   
   <!-- Tag list -->
  
  


    <footer>
        <div class="tag-list">
        
          <div class="meta">Tags</div>
        
            
        
          <a class="button" href="/tags#Mnist">
            <p><i class="fa fa-tag fa-fw"></i> Mnist</p>
          </a>
        
          <a class="button" href="/tags#分类">
            <p><i class="fa fa-tag fa-fw"></i> 分类</p>
          </a>
        
        </div>
    </footer>
  

    
</article>

<!-- Disqus -->

<div class="comments">
  <div id="disqus_thread"></div>
<script type="text/javascript">
	var disqus_shortname = 'phree-dream-1';
	(function() {
		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	})();
</script>
<noscript>启用JavaScript以查看评论.</noscript>

</div>


<!-- Post navigation -->

  <div id="post-nav">
  
  <div id="previous-post" class="post-nav-post">
      <p>上一篇</p>
      <a href="/2018/03/28/setup_opencv_and_basic_usage.html">
        Windows 平台下 Qt OpenCV 环境的配置
      </a>
  </div>
  
  
</div>

    </div>
    
<footer class="site-footer">
    <p class="text">Powered by <a href="https://jekyllrb.com/">Jekyll</a> with <a href="https://github.com/sylhare/Type-on-Strap">Type on Strap</a>
</p>
            <div class="footer-icons">
                <ul>
                <!-- Social icons from Font Awesome, if enabled -->
                
<li>
	<a href="http://localhost:4000////feed.xml" title="订阅RSS">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>



<li>
	<a href="mailto:iphreeliu@gmail.com" title="邮箱">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>













<li>
	<a href="https://github.com/phreer" title="关注 GitHub">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-github fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>
































                </ul>
            </div>
</footer>




  </body>
</html>
